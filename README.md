# üß† RAG-Retriever  

A modular retriever pipeline for **Retrieval-Augmented Generation (RAG)** ‚Äî focusing on data loading, semantic chunking, embedding generation, vector storage, reranking, and retrieval evaluation.  

GitHub: [https://github.com/vishalsharma1996/rag-retriever](https://github.com/vishalsharma1996/rag-retriever)

---
## üìÇ Project Structure
rag-retriever/
‚îú‚îÄ‚îÄ src/
‚îÇ ‚îú‚îÄ‚îÄ init.py
‚îÇ ‚îú‚îÄ‚îÄ data_loader.py # Load and preprocess raw data
‚îÇ ‚îú‚îÄ‚îÄ is_long_doc.py # Identify documents exceeding token limits
‚îÇ ‚îú‚îÄ‚îÄ actual_splitter.py # Split long texts recursively
‚îÇ ‚îú‚îÄ‚îÄ data_combine.py # Combine split + short docs
‚îÇ ‚îú‚îÄ‚îÄ model_inference.py # Retrieve relevant documents
‚îÇ ‚îú‚îÄ‚îÄ evaluate.py # Evaluate retrieval performance
‚îÇ ‚îî‚îÄ‚îÄ ... (other helper modules)
‚îú‚îÄ‚îÄ requirements.txt # Python dependencies
‚îú‚îÄ‚îÄ Dockerfile # (optional) for containerized setup
‚îî‚îÄ‚îÄ main.py # Entry point ‚Äî orchestrates the full pipeline


---

## üéØ Pipeline Overview

- Loads and cleans financial corpora & queries  
- Detects long documents (>300 tokens)  
- Splits them using **RecursiveCharacterTextSplitter**  
- Generates embeddings with **SentenceTransformer (`fin-mpnet-base`)**  
- Stores vector representations in **ChromaDB**  
- Retrieves top-k documents per query  
- Reranks results with **CrossEncoder (`BAAI/bge-reranker-large`)**  
- Evaluates performance (Recall, Precision, F1)  

---

## ‚öôÔ∏è Quick Start (Colab / Local)pip install -r requirements.txt

### 1. Clone the repository
```bash
git clone https://github.com/vishalsharma1996/rag-retriever.git
cd rag-retriever
2. Install dependencies
pip install -r requirements.txt
3. Download NLTK data
import nltk
nltk.download('punkt_tab')
4. Run the main pipeline
python main.py
